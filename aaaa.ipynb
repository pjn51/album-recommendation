{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fifth-scholarship",
   "metadata": {},
   "source": [
    "# Adjective-Assisted Album Aggregator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-replacement",
   "metadata": {},
   "source": [
    "I want to create a web app where a user can enter various adjectives and recieve recommendations for music based on those adjectives. For example, if a user entered \"dreamy,\" \"atmospheric,\" and \"sleepy,\" they might get a Beach House album recommended to them, because maybe a review said those adjectives.\n",
    "\n",
    "This will be powered by a web scraped database of Pitchfork album reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adult-curtis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from textblob import TextBlob\n",
    "from IPython.display import clear_output\n",
    "from PyDictionary import PyDictionary\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-final",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "union-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjScraper(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    blob = TextBlob(soup.text)\n",
    "    \n",
    "    sentence = [word for (word,tag) in blob.tags if tag == 'JJ']\n",
    "    \n",
    "    sentence2 = ' '.join(sentence)\n",
    "    \n",
    "    return sentence2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "asian-turning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullScraper(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    # pulling adjectives\n",
    "    blob = TextBlob(soup.text)\n",
    "    adj_list = [word for (word, tag) in blob.tags if tag == 'JJ']\n",
    "    adj = ' '.join(adj_list)\n",
    "    \n",
    "    # pulling title\n",
    "    title = soup.head.find('title').text\n",
    "    \n",
    "    # pulling score\n",
    "    score = soup.body.find('span', class_='score').text\n",
    "    \n",
    "    return [title, score, adj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sufficient-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nameScraper(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    text = soup.text.strip()\n",
    "    \n",
    "    blob = TextBlob(soup.text)\n",
    "    \n",
    "    name = soup.head.find('title').text\n",
    "    \n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "otherwise-forth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoreScraper(url):\n",
    "    response = requests.get(url)\n",
    "    page = response.text\n",
    "    soup = BeautifulSoup(page, 'lxml')\n",
    "    \n",
    "    score = soup.body.find('span', class_='score').text\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "black-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_albums(n_pages):\n",
    "    '''\n",
    "    This function retrieves names, scores, and adjectives from a\n",
    "    number of pages of Pitchfork album reviews. It returns a pandas\n",
    "    DataFrame of results. \n",
    "    \n",
    "    n_pages (int): the number of pages to scrape. \n",
    "    '''\n",
    "    \n",
    "    # generating list of album review links\n",
    "    links = []\n",
    "    \n",
    "    for i in range(1,n_pages):\n",
    "        url = f'https://pitchfork.com/reviews/albums/?page={i}'\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "\n",
    "        for link in soup.findAll('a'):\n",
    "            link = link.get('href')\n",
    "            if '/reviews/albums/' in link and '?' not in link and link != '/reviews/albums/':\n",
    "                links.append(link)\n",
    "                \n",
    "        print(f'Pulling album links: {round((i/n_pages)*100)}% done')\n",
    "        clear_output(wait=True)\n",
    "    # now pull name and text from each review\n",
    "    reviews = list()\n",
    "    names = list()\n",
    "    scores = list()\n",
    "    album_n = 0\n",
    "    \n",
    "    for link in links:\n",
    "        url = f'https://pitchfork.com{link}'\n",
    "        review = reviewScraper(url)\n",
    "        name = nameScraper(url)\n",
    "        score = scoreScraper(url)\n",
    "        names.append(name)\n",
    "        reviews.append(review)\n",
    "        scores.append(score)\n",
    "        album_n += 1\n",
    "        \n",
    "        print(f'Scraping albums: {round((album_n/len(links))*100)}% done')\n",
    "        clear_output(wait=True)\n",
    "    \n",
    "    df = pd.DataFrame([names, scores, reviews,]).transpose()\n",
    "    \n",
    "    df.rename(columns = {0:'name',1:'score', 2:'adjs'}, inplace = True)\n",
    "    df['name'] = df['name'].apply(lambda x: x.replace('Album Review | Pitchfork', ''))\n",
    "    \n",
    "    # vectorizing adjectives\n",
    "    corpus = df['adjs'].to_list()\n",
    "    vec = CountVectorizer()\n",
    "    adj_vec = vec.fit_transform(corpus)\n",
    "    adjs = adj_vec.toarray()\n",
    "    adj_df = pd.DataFrame(adjs, columns = vec.get_feature_names())\n",
    "    reviews_vecd = pd.merge(df, adj_df, left_index = True, right_index=True)\n",
    "    reviews_vecd = reviews_vecd.drop(columns='adjs')\n",
    "\n",
    "    # double checking to remove non-adjectives\n",
    "    return reviews_vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "guided-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_album(df, adjs):\n",
    "    result = df\n",
    "    for adj in adjs:\n",
    "        adj = adj.lower()\n",
    "\n",
    "        if adj not in df.columns:\n",
    "            return 'That adjective or combination of adjectives has not appeared in an album review.'\n",
    "        \n",
    "        result = result[result[adj] == 1]\n",
    "        result = result.sort_values(['scores'], ascending=False)\n",
    "    \n",
    "\n",
    "    for index, row in result.head().iterrows():\n",
    "        print(f\"{row['name_x']} -- {row['scores']}\\n\")\n",
    "    \n",
    "    if result.shape[0] == 0:\n",
    "        print('Sorry! No albums fit that description, according to Pitchfork.')\n",
    "        \n",
    "    return result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "successful-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see if we can vectorize this work to speed it up\n",
    "def get_albums2(n_pages):\n",
    "    '''\n",
    "    This function retrieves names, scores, and adjectives from a\n",
    "    number of pages of Pitchfork album reviews. It returns a pandas\n",
    "    DataFrame of results. \n",
    "    \n",
    "    n_pages (int): the number of pages to scrape. \n",
    "    '''\n",
    "    # generating list of album review links\n",
    "    links = pd.Series(dtype='str')\n",
    "    \n",
    "    link_start = time.time()\n",
    "    for i in range(1,n_pages):\n",
    "        url = f'https://pitchfork.com/reviews/albums/?page={i}'\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        #print(page)\n",
    "\n",
    "        for link in soup.findAll('a'):\n",
    "            #print(link)\n",
    "            link = link.get('href')\n",
    "            if '/reviews/albums/' in link and '?' not in link and link != '/reviews/albums/':\n",
    "                #print('appending link')\n",
    "                links = links.append(pd.Series(link))\n",
    "    # now pull name and text from each review\n",
    "    link_end = time.time()\n",
    "    print(f'Scraping took {round((link_end - link_start)/i,2)}s per page')\n",
    "    \n",
    "    reviews = pd.Series(dtype='str')\n",
    "    names = pd.Series(dtype='str')\n",
    "    scores = pd.Series(dtype='str')\n",
    "    \n",
    "    #formatting links for scraping\n",
    "    df = pd.DataFrame(links, columns=['links']).reset_index().drop(columns='index')\n",
    "    df['links'] = df['links'].apply(lambda x: f'https://pitchfork.com{x}')\n",
    "    print('Formatted the links')\n",
    "    \n",
    "    # getting album names\n",
    "    names_start = time.time()\n",
    "    df['name'] = df['links'].apply(lambda x: nameScraper(x).replace('Album Review | Pitchfork', ''))\n",
    "    #df['name'] = df['name'].apply(lambda x: x.replace('Album Review | Pitchfork', ''))\n",
    "    names_end = time.time()\n",
    "    print(f'Getting album names took {round((names_end - names_start)/links.shape[0],2)}s per album.')\n",
    "    \n",
    "    # getting album scores\n",
    "    scores_start = time.time()\n",
    "    df['scores'] = df['links'].apply(lambda x: scoreScraper(x))\n",
    "    scores_end = time.time()\n",
    "    print(f'Getting scores took {round((scores_end - scores_start)/links.shape[0],2)} s per album.')\n",
    "    \n",
    "    # getting adjectives\n",
    "    adj_start = time.time()\n",
    "    df['adjs'] = df['links'].apply(lambda x: adjScraper(x))\n",
    "    adj_end = time.time()\n",
    "    print(f'Getting adjs took {round((adj_end - adj_start)/links.shape[0],2)} s per album.')\n",
    "    \n",
    "    df.drop(columns='links', inplace=True)\n",
    "    \n",
    "    # now time to vectorize the adjectives\n",
    "    \n",
    "    corpus = df['adjs'].to_list()\n",
    "    vec = CountVectorizer()\n",
    "    corpus_vec = vec.fit_transform(corpus)\n",
    "    adjs = corpus_vec.toarray()\n",
    "    print('Vectorized the adjectives')\n",
    "    \n",
    "    adj_df = pd.DataFrame(adjs, columns = vec.get_feature_names())\n",
    "    reviews_vecd = pd.merge(df, adj_df, left_index = True, right_index=True)\n",
    "    reviews_vecd = reviews_vecd.drop(columns='adjs')\n",
    "    \n",
    "    final = time.time()\n",
    "    print(f'\\nOverall process took {round((final - link_start)/links.shape[0],2)} s per album.')\n",
    "    \n",
    "    return reviews_vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "gothic-future",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_albums3(n_pages):\n",
    "    '''\n",
    "    This function retrieves names, scores, and adjectives from a\n",
    "    number of pages of Pitchfork album reviews. It returns a pandas\n",
    "    DataFrame of results. \n",
    "    \n",
    "    n_pages (int): the number of pages to scrape. \n",
    "    '''\n",
    "    # generating list of album review links\n",
    "    links = pd.Series(dtype='str')\n",
    "    \n",
    "    link_start = time.time()\n",
    "    for i in range(1,n_pages):\n",
    "        url = f'https://pitchfork.com/reviews/albums/?page={i}'\n",
    "        response = requests.get(url)\n",
    "        page = response.text\n",
    "        soup = BeautifulSoup(page, 'lxml')\n",
    "        #print(page)\n",
    "\n",
    "        for link in soup.findAll('a'):\n",
    "            #print(link)\n",
    "            link = link.get('href')\n",
    "            if '/reviews/albums/' in link and '?' not in link and link != '/reviews/albums/':\n",
    "                #print('appending link')\n",
    "                links = links.append(pd.Series(link))\n",
    "                \n",
    "    # now pull name and text from each review\n",
    "    link_end = time.time()\n",
    "    print(f'Scraping took {round((link_end - link_start)/i,2)}s per page')\n",
    "    \n",
    "    info = pd.DataFrame()\n",
    "    \n",
    "    #formatting links for scraping\n",
    "    df = pd.DataFrame(links, columns=['links']).reset_index().drop(columns='index')\n",
    "    df['links'] = df['links'].apply(lambda x: f'https://pitchfork.com{x}')\n",
    "    print('Formatted the links')\n",
    "    \n",
    "    # getting album info\n",
    "    info_start = time.time()\n",
    "    df['info'] = df['links'].apply(lambda x: fullScraper(x))\n",
    "    #df['name'] = df['name'].apply(lambda x: x.replace('Album Review | Pitchfork', ''))\n",
    "    info_end = time.time()\n",
    "    print(f'Getting album info took {round((info_end - info_start)/links.shape[0],2)}s per album.')\n",
    "    \n",
    "    df.drop(columns='links', inplace=True)\n",
    "    \n",
    "    # separating album info\n",
    "    sep_start = time.time()\n",
    "    df['title'] = df['info'].apply(lambda x: x[0])\n",
    "    df['score'] = df['info'].apply(lambda x: x[1])\n",
    "    df['adjs'] = df['info'].apply(lambda x: x[2])\n",
    "    sep_end = time.time()\n",
    "    \n",
    "    print(f'Separating album info took {round((sep_end - sep_start)/links.shape[0],2)}s per album.')\n",
    "                                                                                                            \n",
    "    # now time to vectorize the adjectives\n",
    "    corpus = df['adjs'].to_list()\n",
    "    vec = CountVectorizer()\n",
    "    corpus_vec = vec.fit_transform(corpus)\n",
    "    adjs = corpus_vec.toarray()\n",
    "    print('Vectorized the adjectives')\n",
    "    \n",
    "    adj_df = pd.DataFrame(adjs, columns = vec.get_feature_names())\n",
    "    reviews_vecd = pd.merge(df, adj_df, left_index = True, right_index=True)\n",
    "    reviews_vecd = reviews_vecd.drop(columns=['adjs','info'])\n",
    "    \n",
    "    final = time.time()\n",
    "    print(f'\\nOverall process took {round((final - link_start)/links.shape[0],2)} s per album.')\n",
    "    \n",
    "    return reviews_vecd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "surprised-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_album2(df, adjs):\n",
    "    pydict = PyDictionary()\n",
    "    result = df\n",
    "\n",
    "    for adj in adjs:\n",
    "        syns = pydict.synonym(adj)\n",
    "        syns += [adj]\n",
    "        print(f\"\\nSearching for albums described as {adj.upper()}. Also looking for albums described as: {', '.join(syns[:-1])}.\")\n",
    "        adj_df = pd.DataFrame()\n",
    "\n",
    "        for syn in syns:\n",
    "            if syn in result.columns:\n",
    "                syn_df = result[result[syn] >= 1]\n",
    "                #print(f'There are {syn_df.shape[0]} albums with \"{syn}\"\\n')\n",
    "                adj_df = pd.concat([adj_df, syn_df])\n",
    "\n",
    "        #print(f'The synonyms of {adj} have {adj_df.shape[0]} entries.\\n')\n",
    "\n",
    "        result = pd.merge(result, adj_df, how = 'inner', \n",
    "                          left_index=True, right_index=True,\n",
    "                          suffixes = (None,'_drop')).drop_duplicates()\n",
    "        \n",
    "        #sorting result based on score\n",
    "        result.sort_values('scores', inplace=True, ascending=False)\n",
    "        \n",
    "    # output\n",
    "    print(f'\\nPitchfork has described {result.shape[0]} albums in that way.\\nHere are the top scoring:\\n')\n",
    "    for index, row in result.head().iterrows():\n",
    "        print(f\"{row['name_x']} -- {row['scores']}\\n\")\n",
    "                                                                                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-shark",
   "metadata": {},
   "source": [
    "# Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "interesting-swimming",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping took 1.05s per page\n",
      "Formatted the links\n",
      "Getting album info took 1.34s per album.\n",
      "Separating album info took 0.0s per album.\n",
      "Vectorized the adjectives\n",
      "\n",
      "Overall process took 1.43 s per album.\n"
     ]
    }
   ],
   "source": [
    "df_official = get_albums3(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "choice-lafayette",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 708 entries, 0 to 707\n",
      "Columns: 8825 entries, title_x to судно\n",
      "dtypes: int64(8823), object(2)\n",
      "memory usage: 47.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_official.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eleven-fossil",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Searching for albums described as FAST. Also looking for albums described as: double-quick, speedy, express, hurrying, fastness, smart, quick, red-hot, high-velocity, winged, hot, meteoric, hurried, straightaway, alacritous, speed, scurrying, rapid, fleet, accelerated, immediate, blistering, high-speed, fast-paced, prompt, instant, sudden, instantaneous, windy, swift, swiftness, fast-breaking.\n",
      "\n",
      "Searching for albums described as AGGRESSIVE. Also looking for albums described as: hard-hitting, truculent, vulturous, obstreperous, combative, hostile, battleful, self-assertive, militant, self-asserting, rapacious, assertive, pugnacious, scrappy, in-your-face, raptorial, competitive, vulturine, predatory, ravening, offensive, bellicose, rough, high-pressure.\n",
      "\n",
      "Searching for albums described as PROFANE. Also looking for albums described as: blasphemous, dirty, blue.\n",
      "\n",
      "Pitchfork has described 0 albums in that way.\n",
      "Here are the top scoring:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "find_album2(df_official, ['fast','aggressive'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-lottery",
   "metadata": {},
   "source": [
    "# Saving dataframe 4 l8r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "typical-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_official.to_pickle('/Users/patricknorman/Documents/Python/Data/albums.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "ignored-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_official = pd.read_pickle('/Users/patricknorman/Documents/Python/Data/albums.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-permit",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
